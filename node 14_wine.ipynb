{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1fe1d7",
   "metadata": {},
   "source": [
    "# 14-2. wine dataset 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872581d",
   "metadata": {},
   "source": [
    "## 와인 분류 문제 : 와인 종류 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba810cd",
   "metadata": {},
   "source": [
    "### 데이터 가져오기 및 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed251b5",
   "metadata": {},
   "source": [
    "#### load_wine import 해와서 wine 데이터를 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93708925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "# sklearn 라이브러리의 datasets 패키지에서 load_wine 함수를 임포트함\n",
    "\n",
    "wine = load_wine()\n",
    "# 로드된 wine 데이터셋을 wine 변수에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e25afb",
   "metadata": {},
   "source": [
    "#### wine에는 어떤 정보들이 담겼을지, keys() 라는 메서드로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21defb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()\n",
    "# wine 데이터셋에 담긴 정보 종류 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0afd06",
   "metadata": {},
   "source": [
    "#### 데이터는 wine_data 변수에 저장한 후, 데이터의 크기를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39ef1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "# keys에서 확인한 정보 중 data를 따로 wine_data 변수에 저장\n",
    "\n",
    "print(wine_data.shape) \n",
    "# shape는 배열의 형상정보를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65551e0",
   "metadata": {},
   "source": [
    "### 분석 : \n",
    "178개의 데이터가 각각 13개의 정보를 담고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651cca4",
   "metadata": {},
   "source": [
    "#### 샘플로 하나의 데이터만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5663b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "       1.065e+03])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[0]\n",
    "# 178개의 데이터 중 첫 번째 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0a0f6",
   "metadata": {},
   "source": [
    "#### 라벨(label) 또는 타겟(target) 확인 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98c5d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_label = wine.target\n",
    "# keys에서 확인한 정보 중 target을 따로 wine_label 변수에 저장\n",
    "\n",
    "print(wine_label.shape)\n",
    "wine_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66220522",
   "metadata": {},
   "source": [
    "### 분석:\n",
    "길이와 형태를 확인하니 총 178개의 데이터가 들어있고, 각 값은 0, 1, 2로 나타나는 것을 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a80db3",
   "metadata": {},
   "source": [
    "#### 라벨의 이름을 target_names에서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "580ae9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names\n",
    "# keys에서 확인한 정보 중 target_names를 변수에 따로 저장하지 않고 호출\n",
    "# wine_label이 가진 0, 1, 2의 이름 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3542fc",
   "metadata": {},
   "source": [
    "### 분석:\n",
    "'class_0', 'class_1', 'class_2' 순서대로 담겨있음\n",
    "\n",
    "이 순서 그대로 0이라면 class_0, 1이라면 class_1, 2라면 class_2를 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f58b9",
   "metadata": {},
   "source": [
    "#### feature_names: 13개의 각 feature에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d94b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names\n",
    "# keys에서 확인한 정보 중 feature_names를 변수에 따로 저장하지 않고 호출\n",
    "# wine.data에서 확인한 30개 정보의 변수명 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0581600",
   "metadata": {},
   "source": [
    "#### 데이터셋을 DataFrame으로 변환\n",
    "\n",
    "DataFrame 을 만들면서 data에는 wine_data 넣어주고, 각 컬럼에는 feature_names로 이름을 붙여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ee1e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3aed5b",
   "metadata": {},
   "source": [
    "#### label(정답) 컬럼을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f35a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[\"label\"] = wine.target\n",
    "# wine_df에 label이라는 컬럼을 새로 추가\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87e2d8",
   "metadata": {},
   "source": [
    "#### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe8d213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "label                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64d20a",
   "metadata": {},
   "source": [
    "### 분석:\n",
    "데이터에서 결측치는 찾을 수 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8b4d8",
   "metadata": {},
   "source": [
    "#### 학습에 사용하는 training dataset과 모델의 성능을 평가하는 데 사용하는 test dataset으로 데이터셋을 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd79d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (142,), (36, 13), (36,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn model_selection패키지의 train_test_split 함수를 임포트\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "# 나눠야 할 데이터(문제지, X): wine_data\n",
    "# 데이터의 라벨(정답, y): wine_label\n",
    "# wine_data, wine_label 각각 train:test = 8:2의 비율로 잘라서 \n",
    "# X_train, X_test, y_train, y_test에 저장\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "# train의 형상정보 확인 # test의 형상정보 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f64af",
   "metadata": {},
   "source": [
    "### 머신러닝 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5647d",
   "metadata": {},
   "source": [
    "## DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0432e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # 싸이킷런에 있는 결정트리분류기를 사용하기 위해 불러오는 코드\n",
    "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=1) #결정트리분류기의 객체를 만든다.\n",
    "decision_tree.fit(X_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred = decision_tree.predict(X_test) # 훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인한다.\n",
    "\n",
    "decision_report = classification_report(y_test, y_pred) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인한다.\n",
    "print(decision_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfffb7",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b111bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.95      0.98      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위해 import\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=2) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test) # 예측\n",
    "\n",
    "\n",
    "random_report = classification_report(y_test, y_pred)\n",
    "print(random_report) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e062e",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd27c5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.80      0.75      0.77        16\n",
      "           2       0.38      0.50      0.43         6\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.72      0.73      0.72        36\n",
      "weighted avg       0.81      0.78      0.79        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
    "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
    "\n",
    "svm_model.fit(X_train, y_train) # 훈련\n",
    "y_pred = svm_model.predict(X_test) # 예측\n",
    "\n",
    "svm_report = classification_report(y_test, y_pred)\n",
    "print(svm_report) # 결과 지표를 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45ad9a",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier (SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec6df8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74        14\n",
      "           1       0.82      0.56      0.67        16\n",
      "           2       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.80      0.58      0.56        36\n",
      "weighted avg       0.76      0.67      0.63        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "y_pred = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "sgd_report = classification_report(y_test, y_pred)\n",
    "print(sgd_report) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccf5fd",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbd6cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.93      0.88      0.90        16\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 선형분류기인 LogisticRegression를 사용하기 위한 import\n",
    "logistic_model = LogisticRegression() # 모델 객체 생성\n",
    "\n",
    "logistic_model.fit(X_train, y_train) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred = logistic_model.predict(X_test) # 예측\n",
    "\n",
    "logistic_report = classification_report(y_test, y_pred)\n",
    "print(logistic_report) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fea99f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Decision Tree >\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "< Random Forest >\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.95      0.98      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "< SVM >\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.80      0.75      0.77        16\n",
      "           2       0.38      0.50      0.43         6\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.72      0.73      0.72        36\n",
      "weighted avg       0.81      0.78      0.79        36\n",
      "\n",
      "< SGD >\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74        14\n",
      "           1       0.82      0.56      0.67        16\n",
      "           2       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.80      0.58      0.56        36\n",
      "weighted avg       0.76      0.67      0.63        36\n",
      "\n",
      "< Logistic Regression >\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.93      0.88      0.90        16\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### 다양한 모델들의 예측값의 결가지표 비교하기\n",
    "print('< Decision Tree >')\n",
    "print(decision_report)\n",
    "\n",
    "print('< Random Forest >')\n",
    "print(random_report)\n",
    "\n",
    "print('< SVM >')\n",
    "print(svm_report)\n",
    "\n",
    "print('< SGD >')\n",
    "print(sgd_report)\n",
    "\n",
    "print('< Logistic Regression >')\n",
    "print(logistic_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88e867a2",
   "metadata": {},
   "source": [
    "### 분석:\n",
    "\n",
    "실습의 목표는 와인의 종류를 분류하여 찾아내는 것이다.\n",
    "\n",
    "조금 더 세부적인 상황으로 와인의 특징을 기입하고 해당 와인이 A종류의 와인인지 확인하여 출고하는 경우라고 가정하자.\n",
    "\n",
    "이 경우 실제 A종류의 와인인데 아니라고 잘못된 판단을 하는 것보다 B종류의 와인을 A종류의 와인이라고 하는 잘못 판단하는 경우가 더 치명적인 상황이 될 것이다. 따라서 오류라도 현재 가정된 상황에서는 positive를 잡아내는 데에 실패하는 오류보다 negative를 잡아내는 데에 실패하는 오류의 치명도와 중요도가 훨씬 크다. \n",
    "\n",
    "현재 가정된 상황에서는 실제 negative인데 positive로 잘못 판단하는 경우가 가장 치명적인 오류이고, 이 경우가 가장 적어야한다. 따라서 FP이 낮을수록 수치가 커지는 Precision 값이 가장 중요한 척도라고 할 수 있다.\n",
    "\n",
    "   \n",
    "위의 각 모델 예측 결과의 confusion matrix를 살펴보면,\n",
    "\n",
    "    Decision Tree의 경우 각 와인의 종류별로 precision 값이 0.93, 1.00, 1.00이고 f1-score는 0.97, 0.97, 1.00이다.\n",
    "    \n",
    "    Random Forest의 경우 각 와인의 종류별로 precision 값이 1.00, 1.00, 0.86, 이고 f1-score는 1.00, 0.97, 0.92이다.\n",
    "\n",
    "    SVM의 경우 각 와인의 종류별로 precision 값이 1.00, 0.80, 0.38, 이고 f1-score는 0.96, 0.77, 0.43이다.\n",
    "\n",
    "    SGD의 경우 각 와인의 종류별로 precision 값이 0.58, 0.82, 1.00, 이고 f1-score는 0.74, 0.67, 0.29이다.\n",
    "\n",
    "    Logistic Regression의 경우 각 와인의 종류별로 precision 값이 0.93, 0.93, 0.86, 이고 f1-score는 0.93, 0.90, 0.92이다.\n",
    "\n",
    "#### 즉, 정확도도 높으며 거짓 양성 판정의 확률도 가장 적은 Decision Tree모델이 가장 적절한 예측 모델이라고 할 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495858f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
